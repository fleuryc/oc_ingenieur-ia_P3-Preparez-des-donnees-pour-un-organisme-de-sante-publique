{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_See [Readme](https://github.com/fleuryc/oc_ingenieur-ia_P2-Participez-a-un-concours-sur-la-Smart-City#readme) for installation instructions_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santé Publique France : rendre les données de santé publique plus accessibles\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Santé Publique France (SPF) souhaite mettre à disposition de ses agents des informations plus claires, lisibles et accessibles que les données brutes disponibles. Nous allons ici étudier les données Open Food Facts afin de les aider à mieux observer et comprendre quels sont les enjeux et problématiques de santé publique liés aux produits alimentaires de la grande distribution.\n",
    "\n",
    "L'objectif est donc ici de produire des analyses graphiques pertinentes et parlantes au plus grand nombre.\n",
    "\n",
    "\n",
    "## Outils utilisés\n",
    "\n",
    "Nous allons utiliser le langage Python, et présenter ici le code, les résultats et l'analyse sous forme de [Notebook Jupyter](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html).\n",
    "\n",
    "Nous allons aussi utiliser les bibliothèques usuelles d'exploration et analyse de données, afin d'améliorer la simplicité et la performance de notre code :\n",
    "  * [NumPy](https://numpy.org/doc/stable/user/quickstart.html) et [Pandas](https://pandas.pydata.org/docs/user_guide/index.html) : effectuer des calculs scientifiques (statistiques, algèbre, ...) et manipuler des séries et tableaux de données volumineuses et complexes\n",
    "  * [Matplotlib](https://matplotlib.org/stable/tutorials/introductory/usage.html), [Pyplot](https://matplotlib.org/stable/tutorials/introductory/pyplot.html), [Seaborn](https://seaborn.pydata.org/tutorial/function_overview.html) et [Plotly](https://plotly.com/python/getting-started/) : générer des graphiques lisibles, intéractifs et pertinents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6fgKy6soGU0"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# System libraries to import the data\n",
    "import os.path \n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Math libraries to process the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graph libraries to produce graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "## If you use Notebook (and not JupyterLab), uncomment following lines\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default='notebook'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données et premier aperçu\n",
    "\n",
    "Les données mises à disposition sont issues de [Open Food Facts](https://world.openfoodfacts.org/) et présentent les données sur les produits alimentaires.\n",
    "\n",
    "Nous allons télécharger et extraire le fichier ZIP, puis effectuer une première passe afin de traiter les irrégularités du fichier, avant de charger les données et observer quelques valeurs.\n",
    "\n",
    "\n",
    "### Téléchargement et extraction des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ZIP and extract CSV\n",
    "data_local_path = 'data/'\n",
    "csv_filename = 'fr.openfoodfacts.org.products.csv'\n",
    "csv_local_path = data_local_path+csv_filename\n",
    "\n",
    "if not os.path.isfile(csv_local_path):\n",
    "    zip_filename = csv_filename+'.zip'\n",
    "    zip_url = 'https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/parcours-data-scientist/P2/'+zip_filename\n",
    "    zip_local_path = data_local_path+zip_filename\n",
    "\n",
    "    with urlopen(zip_url) as zip_response:\n",
    "        with ZipFile(BytesIO(zip_response.read())) as zip_file:\n",
    "            # extract all files do local data/ directory\n",
    "            zip_file.extractall(data_local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion des irrégularités du fichier CSV téléchargé\n",
    "\n",
    "Le fichier contenant les données est mal formé à plusieurs endroits : des sauts de ligne sont présents dans 23 lignes à la fin de la colonne `first_packaging_code_geo`. Ces irrégularités sont facilement repérables car ce sont les seules lignes qui ne commencent pas par le code de l'article (`code`), mais par un séparateur `\\t`. Nous allons donc corriger ces irrégularités en supprimant les sauts de ligne superflus, puis écrire les données propres dans un nouveau fichier CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_filename = 'fr.openfoodfacts.org.products-clean.csv'\n",
    "clean_local_path = data_local_path+clean_filename\n",
    "\n",
    "if not os.path.isfile(clean_local_path):\n",
    "    with open(csv_local_path, 'r') as csv_file, open(clean_local_path, 'w') as clean_file:\n",
    "        \"\"\" Deal with irregularities\n",
    "\n",
    "            23 data points are wrongly split into two lines : \n",
    "            - lines : 189070, 189105, 189111, 189121, 189154, 189162, 189164, 189170, 189244, 189246, \n",
    "                    189250, 189252, 189262, 189264, 189271, 189274, 189347, 189364, 189366, 189381, \n",
    "                    189406, 189408, 189419\n",
    "            \n",
    "            The pattern is always the same : \n",
    "            - a NewLine character (`\\n`) is placed at the end of column \"first_packaging_code_geo\" \n",
    "            - and the next line starts with a TAB separator (`\\t`) : column \"cities\" is empty.\n",
    "            \n",
    "            Since the first column (\"code\") is never empty, we just remove any `\\n` character that is \n",
    "            directly followed by a TAB separator (`\\t`).\n",
    "        \"\"\"\n",
    "\n",
    "        data = csv_file.read()\n",
    "        clean_file.write(data.replace('\\n\\t', '\\t'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "\n",
    "Nous allons charger les données en mémoire et convertir les valeurs dans le bon type, selon les [spécifications fournies](https://static.openfoodfacts.org/data/data-fields.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read column names\n",
    "column_names = pd.read_csv(clean_local_path, sep='\\t', encoding='utf-8', nrows=0).columns.values\n",
    "\n",
    "# Set column types according to fields description (https://static.openfoodfacts.org/data/data-fields.txt)\n",
    "column_types = {col: 'Int64' for (col) in column_names if col.endswith(('_t', '_n'))}\n",
    "column_types |= {col: float for (col) in column_names if col.endswith(('_100g', '_serving'))}\n",
    "column_types |= {col: str for (col) in column_names if not col.endswith(('_t', '_n', '_100g', '_serving', '_tags'))}\n",
    "\n",
    "tags_converter = lambda list_as_string_value : list_as_string_value.split(',') if list_as_string_value else pd.NA\n",
    "\n",
    "# Load raw data\n",
    "raw_data = pd.read_csv(clean_local_path, sep='\\t', encoding='utf-8',\n",
    "    dtype=column_types,\n",
    "    parse_dates=[col for (col) in column_names if col.endswith('_datetime')],\n",
    "    infer_datetime_format=True,\n",
    "    converters={\n",
    "        # Convert '_tags' columns into list of values (separator : ',')\n",
    "        col: tags_converter\n",
    "        for (col) in column_names if col.endswith('_tags')\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display DataFrame size\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier de données fourni contient 162 variables pour 320749 individus.\n",
    "\n",
    "\n",
    "### Sélection des données pertinentes\n",
    "\n",
    "Nous allons chercher à n'utiliser que les variables pertinentes pour SPF : celles pour lesquelles nous avons suffisament de valeurs non vides pour pouvoir faire une analyse statistique fiable, et qui peuvent avoir un réel sens du point de vue des problématiques de santé publique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_empty_values(dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\" Plot a histogram of empty values percentage per columns of the input DataFrame\n",
    "    \"\"\"\n",
    "    num_rows = len(dataframe.index)\n",
    "    columns_emptiness = pd.DataFrame({\n",
    "        col : { \n",
    "            'count': dataframe[col].isna().sum(),\n",
    "            'percent': 100 * dataframe[col].isna().sum() / num_rows,\n",
    "        } for col in dataframe.columns\n",
    "    }).transpose().sort_values(by=['count'])\n",
    "\n",
    "    fig = px.bar(columns_emptiness,\n",
    "        color='percent',\n",
    "        y='percent',\n",
    "        labels={\n",
    "            'index':'column name',\n",
    "            'percent':'% of empty values',\n",
    "            'count':'# of empty values',\n",
    "        },\n",
    "        hover_data=['count'],\n",
    "        title='Empty values per column',\n",
    "        width=1200,\n",
    "        height=600,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_empty_values(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que un grand nombre de variables ont un taux de complétude très faible et ne seront donc pas utilisables.\n",
    "Nous allons donc restreindre notre analyse aux variables utilisées pour le calcul du [Nutri Score](https://www.santepubliquefrance.fr/determinants-de-sante/nutrition-et-activite-physique/articles/nutri-score), qui est un indicateur très parlant du point de vue de la santé.\n",
    "\n",
    "\n",
    "### Premier aperçu\n",
    "\n",
    "Affichons quelques informations et les premières vaeulrs observées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep only meaningful columns\n",
    "meaningful_columns = [\n",
    "    # General information\n",
    "    'code', 'product_name', 'main_category', 'additives_n', \n",
    "\n",
    "    # Nutri-Score\n",
    "    'nutrition_grade_fr', 'nutrition-score-fr_100g',\n",
    "\n",
    "    # Positive nutrition facts\n",
    "    'energy_100g', 'saturated-fat_100g', 'sugars_100g', 'salt_100g', 'sodium_100g',\n",
    "\n",
    "    # Negative nutrition facts \n",
    "    'fruits-vegetables-nuts_100g', 'fiber_100g', 'proteins_100g',\n",
    "]\n",
    "meaningful_data = raw_data.loc[:, meaningful_columns].copy()\n",
    "\n",
    "# Display DataFrame size\n",
    "meaningful_data.info()\n",
    "\n",
    "# Display first values of each column\n",
    "meaningful_data.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Première analyse statistique\n",
    "\n",
    "Voyons quelle est la répartition des différentes variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary of each column\n",
    "meaningful_data.describe(include=\"all\", datetime_is_numeric=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution des différentes valeurs\n",
    "\n",
    "Voyons comment sont distribuées certaines variables.\n",
    "\n",
    "\n",
    "### Variable catégorique nominale : `main_category`\n",
    "\n",
    "Voyons comment sont réparties les catégories de produits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the density of product categories\n",
    "fig = px.line(raw_data['main_category'].value_counts())\n",
    "fig.update_layout(\n",
    "    title_text=\"Product categories\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons déjà qu'il y a une répartition très inégale des catégories de produits et qu'il faudrait certainement améliorer la catégorisation afin d'éviter d'avoir un très grand nombre de catégories à 1 seul élément.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep only the top values and merge the rest into \"Other\"\n",
    "meaningful_data.loc[:,'top_category'] = raw_data['main_category'].where(\n",
    "    raw_data['main_category'].isna() | raw_data['main_category'].isin(raw_data['main_category'].value_counts().index[:20]), \n",
    "    other='other', \n",
    ")\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2, \n",
    "    subplot_titles=(\"Top 20 with 'other'\", \"Top 20\"), \n",
    "    specs=[[{'type':'domain'}, {'type':'domain'}]],\n",
    ")\n",
    "fig.add_trace(go.Pie(\n",
    "    labels=meaningful_data['top_category'].value_counts().index, \n",
    "    values=meaningful_data['top_category'].value_counts().values, \n",
    "    name=\"Including 'other'\",\n",
    "    pull=[0.05 if cat == 'other' else 0 for cat in meaningful_data['top_category'].value_counts().index],\n",
    "), row=1, col=1)\n",
    "fig.add_trace(go.Pie(\n",
    "    labels=meaningful_data['top_category'].value_counts().index[1:], \n",
    "    values=meaningful_data['top_category'].value_counts().values[1:], \n",
    "    name=\"Top 20\",\n",
    "), row=1, col=2)\n",
    "fig.update_traces(\n",
    "    textposition='inside',\n",
    "    textinfo='percent+label'\n",
    ")\n",
    "fig.update_layout(\n",
    "    title_text=\"Product categories\",\n",
    "    width=1200,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que les 20 catégories les plus représentées représentent près de 50% de toutes les valeurs. De même, les 5 premières catégories représentent plus de 80% des 3543 valeurs possibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variable catégorique ordinale : `nutrition_grade_fr`\n",
    "\n",
    "Voyons comment sont réparties les notes de Nutri-Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUTRITION_GRADES = ('a', 'b', 'c', 'd', 'e')\n",
    "\n",
    "# Display the nutrition grade distribution per product category\n",
    "fig = px.histogram(meaningful_data.loc[meaningful_data['top_category'].notnull() & meaningful_data['nutrition_grade_fr'].notnull()],\n",
    "    x='nutrition_grade_fr',\n",
    "    category_orders={'nutrition_grade_fr': NUTRITION_GRADES},\n",
    "    color='top_category',\n",
    "    title='Global nutrition grade repartition',\n",
    "    width=1200,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que parmis les produits répertoriés, la répartition des produits par Nutri-Score est globalement comparable, avec une sur-représentation des labels C et D .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the product category distribution by nutrition grade\n",
    "fig = px.histogram(meaningful_data.loc[meaningful_data['top_category'] != 'other'].loc[meaningful_data['top_category'].notnull() & meaningful_data['nutrition_grade_fr'].notnull()],\n",
    "    x='top_category',\n",
    "    category_orders={'nutrition_grade_fr': NUTRITION_GRADES},\n",
    "    color='nutrition_grade_fr',\n",
    "    histnorm='percent',\n",
    "    width=1200,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the heatmap of top product categories per nutrition grade\n",
    "table = meaningful_data.loc[meaningful_data['top_category'] != 'other'].pivot_table(\n",
    "    values='code',\n",
    "    index='top_category',\n",
    "    columns='nutrition_grade_fr',\n",
    "    aggfunc='count',\n",
    "    fill_value=0,\n",
    "    observed=True,\n",
    ").sort_values(by=list(NUTRITION_GRADES))\n",
    "\n",
    "fig = px.imshow(table,\n",
    "    title=\"Nutri-Score grade for top 20 product categories\",\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons déjàa que parmis les 20 types de produits les plus représentés, ceux présentant un meilleur Nutri-Score sont les produits en boîte, les produits à base de plantes et les pâtes. Les légumes frais sont le plus souvent de Nutri-Score A, tandis que les chocolats, bonbons, biscuits et en-cas sucrés ont le plus souvent un mauvais Nutri-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables numérique\n",
    "\n",
    "Nous allons dans un premier temps nettoyer les données numérique, avant d'en étudier la répartition. Ceci permettra d'avoir des données plus fiables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage : suppression des données aberrantes\n",
    "\n",
    "Parmis les données fournies, nous voyons des valeurs négatives pour des variables comme le nombre d'additifs, ou la quantité de sucre pour 100g de produit, ce qui est impossible.\n",
    "Nous allons aussi utiliser la méthode IQR (Inter Quartile Range) pour identifier les données aberrantes (outliers) et les supprimer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_negative_values(dataframe: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\" Remove negative values from specified columns of DataFrame\n",
    "    \"\"\"\n",
    "    df = dataframe.copy()\n",
    "    for col in columns:\n",
    "        df.loc[:,col] = dataframe[col].where(dataframe[col] >= 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "positive_columns = [\n",
    "    'additives_n', \n",
    "    'energy_100g', 'saturated-fat_100g', 'sugars_100g', 'salt_100g', 'sodium_100g',\n",
    "    'fruits-vegetables-nuts_100g', 'fiber_100g', 'proteins_100g',\n",
    "]\n",
    "\n",
    "clean_data = remove_negative_values(meaningful_data, positive_columns)\n",
    "\n",
    "clean_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons bien supprimé les valeurs négatives impossibles, mais nous voyons encore des valeurs maximum aberrantes (ex. : 550g d'acides gras saturés pour 100g de produit).\n",
    "Nous allons donc supprimer les valeurs aberrantes restantes grâce à la méthode IQR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(dataframe: pd.DataFrame, columns: list[str]) -> pd.DataFrame:\n",
    "    \"\"\" Remove outlier values from specified columns of DataFrame\n",
    "\n",
    "        Compute the Inter-Quartile Ranges and set outliers to NaN\n",
    "    \"\"\"\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # compute quartiles and define range\n",
    "    quartiles = df[columns].quantile([0.25, 0.75])\n",
    "    iqr = quartiles.loc[0.75]-quartiles.loc[0.25]\n",
    "    limits = pd.DataFrame({\n",
    "        col: [\n",
    "            quartiles.loc[0.25, col] - 1.5 * iqr[col], # min\n",
    "            quartiles.loc[0.75, col] + 1.5 * iqr[col], # max\n",
    "        ] for col in columns\n",
    "    }, index=['min', 'max'])\n",
    "\n",
    "    # set to NaN data that are outside the range\n",
    "    for col in columns:\n",
    "        df.loc[:,col] = dataframe[col].where(\n",
    "            limits.loc['min', col] <= dataframe[col]\n",
    "        ).where(\n",
    "            dataframe[col] <= limits.loc['max', col]\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "numeric_columns = positive_columns.copy()\n",
    "numeric_columns.append('nutrition-score-fr_100g')\n",
    "\n",
    "clean_data = remove_outliers(clean_data, numeric_columns)\n",
    "\n",
    "clean_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant des valeurs qui semblent correctes. Observons leur répartition avant de compléter les valeurs vides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to plot multiple BoxPlots\n",
    "def draw_boxplots(dataframe: pd.DataFrame, categorical_column: str, numerical_columns: list[str], order_values: tuple[str]) -> None:\n",
    "    \"\"\" Draw one boxplot per numerical variable, split per categories.\n",
    "\n",
    "        Arguments :\n",
    "        - dataframe : Pandas DataFrame containing the data, including the categorical_column and numerical_columns\n",
    "        - categorical_column : string representing the name of the variable containing the categories\n",
    "        - numerical_columns : list of strings representing the name of the numerical variables to plot\n",
    "        - order_values : list of strings representing the values of the numerical variables to plot\n",
    "\n",
    "        Returns : None\n",
    "    \"\"\"\n",
    "    num_cols = 3\n",
    "    num_lines = int(np.ceil(len(numerical_columns) / 3))\n",
    "    fig, axes = plt.subplots(num_lines, num_cols, figsize=(8 * num_cols , 8 * num_lines))\n",
    "    fig.suptitle(f'Numeric variables distribution, per { categorical_column }', fontsize=24)\n",
    "\n",
    "    for i, col in enumerate(numerical_columns):\n",
    "        sns.boxplot(data=dataframe,\n",
    "            x=categorical_column, \n",
    "            y=col,\n",
    "            order=order_values,\n",
    "            ax=axes[int(np.floor(i / num_cols)), i % num_cols],\n",
    "        )\n",
    "\n",
    "# Draw the BoxPlots of each numeric column, split per Nutrition Grade\n",
    "draw_boxplots(\n",
    "    dataframe=clean_data, \n",
    "    categorical_column='nutrition_grade_fr', \n",
    "    numerical_columns=numeric_columns, \n",
    "    order_values=NUTRITION_GRADES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons qu'il y a encore des données aberrantes, notamment en analysant les données selon la note de Nutri-Score.\n",
    "Nous allons donc à nouveau supprimer ces données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work on a copy of our clean data\n",
    "super_clean_data = clean_data.copy()\n",
    "\n",
    "for grade in NUTRITION_GRADES:\n",
    "    # for each nutrition grade, \n",
    "    # we remove the outliers of each numeric column detected \n",
    "    # after filtering the data by nutrition grade\n",
    "    super_clean_data.loc[super_clean_data['nutrition_grade_fr'] == grade] = remove_outliers(clean_data.loc[clean_data['nutrition_grade_fr'] == grade], numeric_columns)\n",
    "\n",
    "super_clean_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw the BoxPlots again after more data cleaning\n",
    "draw_boxplots(\n",
    "    dataframe=super_clean_data, \n",
    "    categorical_column='nutrition_grade_fr', \n",
    "    numerical_columns=numeric_columns, \n",
    "    order_values=NUTRITION_GRADES\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons maintenant que les données sont quasiment toutes contenues dans les \"moustaches\" des boxplots, autrement dit il n'y a presque plus de données aberrantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nettoyage : suppression des doublons et lignes vides\n",
    "\n",
    "Il est inutile de conserver des données en doublons, nous allons donc supprimer ces lignes. En l'occurrence, comme le `code` est unique à chaque produit, il ne peut pas y avoir de lignes en doublon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count duplucated lines\n",
    "duplicates = super_clean_data.duplicated()\n",
    "duplicates.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la suite, toute notre analyse va se baser sur le paramètre `nutrition_grade_fr`. Nous allons supprimer les lignes où la valeur de cette variable est vide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop raws where nutrition_grade_fr is empty\n",
    "nutrition_data = super_clean_data.dropna(subset=['nutrition_grade_fr']).copy()\n",
    "plot_empty_values(nutrition_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Nettoyage : remplacement des valeurs manquantes\n",
    "\n",
    "Nous pouvons alors considérer les données restantes comme fiables, et nous allons nous baser sur ces valeurs pour extrapoler les valeurs manquantes dans notre jeu de données.\n",
    "Nous allons remplacer, pour chaque valeur numérique vide, la valeur moyenne des individus ayant la même note de Nutri-Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = nutrition_data.groupby('nutrition_grade_fr').mean()\n",
    "means.loc[:,'additives_n'] = means['additives_n'].map(np.round)\n",
    "\n",
    "for grade in means.index:\n",
    "    nutrition_data.loc[nutrition_data['nutrition_grade_fr'] == grade] = nutrition_data[nutrition_data['nutrition_grade_fr'] == grade].fillna(\n",
    "        value=means.loc[grade]\n",
    "    )\n",
    "\n",
    "plot_empty_values(nutrition_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw the BoxPlots again after more data cleaning\n",
    "draw_boxplots(\n",
    "    dataframe=nutrition_data, \n",
    "    categorical_column='nutrition_grade_fr', \n",
    "    numerical_columns=numeric_columns, \n",
    "    order_values=NUTRITION_GRADES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(nutrition_data.sample(frac=.01),\n",
    "    dimensions=[\n",
    "        'energy_100g', \n",
    "        'saturated-fat_100g', \n",
    "        'sugars_100g', \n",
    "        'salt_100g', \n",
    "        'nutrition-score-fr_100g',\n",
    "    ],\n",
    "    color=\"nutrition_grade_fr\", symbol=\"nutrition_grade_fr\",\n",
    "    category_orders={\n",
    "        'nutrition_grade_fr': NUTRITION_GRADES,\n",
    "    },\n",
    "    opacity=.1,\n",
    "    width=1200,\n",
    "    height=1200,\n",
    ")\n",
    "fig.update_traces(\n",
    "    showupperhalf=False,\n",
    "    diagonal_visible=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(nutrition_data.sample(frac=.01),\n",
    "    dimensions=[\n",
    "        'nutrition-score-fr_100g',\n",
    "        'fruits-vegetables-nuts_100g', \n",
    "        'fiber_100g',\n",
    "        'proteins_100g',\n",
    "    ],\n",
    "    color=\"nutrition_grade_fr\", symbol=\"nutrition_grade_fr\",\n",
    "    category_orders={\n",
    "        'nutrition_grade_fr': NUTRITION_GRADES,\n",
    "    },\n",
    "    opacity=.1,\n",
    "    width=1200,\n",
    "    height=1200,\n",
    ")\n",
    "fig.update_traces(\n",
    "    showupperhalf=False,\n",
    "    diagonal_visible=False,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_nutrition_data = nutrition_data.copy()\n",
    "normalized_nutrition_data[numeric_columns]=(nutrition_data[numeric_columns]-nutrition_data[numeric_columns].min())/(nutrition_data[numeric_columns].max()-nutrition_data[numeric_columns].min())\n",
    "\n",
    "fig = px.scatter(normalized_nutrition_data.sample(frac=.01),\n",
    "    x=[\n",
    "        'additives_n', \n",
    "        'energy_100g', \n",
    "        'saturated-fat_100g', \n",
    "        'sugars_100g', \n",
    "        'salt_100g', \n",
    "        # 'sodium_100g',\n",
    "        # 'nutrition-score-fr_100g',\n",
    "        'fruits-vegetables-nuts_100g', \n",
    "        'fiber_100g',\n",
    "        'proteins_100g',\n",
    "    ],\n",
    "    y='nutrition-score-fr_100g',\n",
    "    # color=\"nutrition_grade_fr\", symbol=\"nutrition_grade_fr\",\n",
    "    # category_orders={'nutrition_grade_fr': NUTRITION_GRADES},\n",
    "    trendline='ols',\n",
    "    opacity=.1,\n",
    "    width=1200,\n",
    "    height=1200,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_columns = [\n",
    "    'brands_tags', 'countries_tags',\n",
    "]\n",
    "\n",
    "brands_freq = pd.Series([x for _list in raw_data['brands_tags'].dropna() for x in _list]).value_counts()\n",
    "countries_freq = pd.Series([x for _list in raw_data['countries_tags'].dropna() for x in _list]).value_counts()\n",
    "\n",
    "display(brands_freq, countries_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meaningful_data['coherent_grade_score'] = False\n",
    "\n",
    "meaningful_data.loc[\n",
    "    (( meaningful_data['nutrition_grade_fr'] == 'a' ) \n",
    "        & ( meaningful_data['nutrition-score-fr_100g'] < 0 ))\n",
    "    | (( meaningful_data['nutrition_grade_fr'] == 'b' ) \n",
    "        & (( 0 <= meaningful_data['nutrition-score-fr_100g'] ) \n",
    "            | ( meaningful_data['nutrition-score-fr_100g'] < 3 )))\n",
    "    | (( meaningful_data['nutrition_grade_fr'] == 'c' ) \n",
    "        & (( 3 <= meaningful_data['nutrition-score-fr_100g'] ) \n",
    "            | ( meaningful_data['nutrition-score-fr_100g'] < 11 )))\n",
    "    | (( meaningful_data['nutrition_grade_fr'] == 'd' ) \n",
    "        & (( 11 <= meaningful_data['nutrition-score-fr_100g'] ) \n",
    "            | ( meaningful_data['nutrition-score-fr_100g'] < 19 )))\n",
    "    | (( meaningful_data['nutrition_grade_fr'] == 'e' )\n",
    "        & ( 19 <= meaningful_data['nutrition-score-fr_100g'] ))\n",
    ", 'coherent_grade_score'] = True\n",
    "\n",
    "meaningful_data['coherent_grade_score'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"saturated-fat_100g\", \n",
    "    y=\"sugars_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=['a', 'b', 'c', 'd', 'e'],\n",
    "    height=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expected_score(row):\n",
    "    negative_points = {\n",
    "        'energy_100g': [335, 670, 1005, 1340, 1675, 2010, 2345, 2680, 3015, 3350],\n",
    "        'saturated-fat_100g': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'sugars_100g': [4.5, 9, 13.5, 18, 22.5, 27, 31, 36, 40, 45],\n",
    "        'salt_100g': [90*2.5/1000, 180*2.5/1000, 270*2.5/1000, 360*2.5/1000, 450*2.5/1000, 540*2.5/1000, 630*2.5/1000, 720*2.5/1000, 810*2.5/1000, 900*2.5/1000],\n",
    "    }\n",
    "    positive_points = {\n",
    "        'fruits-vegetables-nuts_100g': [40, 60, 67, 74, 80],\n",
    "        'fiber_100g': [.9, 1.9, 2.8, 3.7, 4.7],\n",
    "        'proteins_100g': [1.6, 3.2, 4.8, 6.4, 8.0],\n",
    "    }\n",
    "\n",
    "    score = 0\n",
    "\n",
    "    for criteria in negative_points:\n",
    "        for value in negative_points[criteria]:\n",
    "            if row[criteria] > value:\n",
    "                score += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    for criteria in positive_points:\n",
    "        for value in positive_points[criteria]:\n",
    "            if row[criteria] > value:\n",
    "                score -= 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# meaningful_data.assign(expected_score = lambda row: expected_score(row), axis=1)\n",
    "# meaningful_data.assign(expected_grade = lambda row: \n",
    "#     'a' if row['expected_score'] < 0 \n",
    "#     else 'b' if row['expected_score'] < 3 \n",
    "#     else 'c' if row['expected_score'] < 11 \n",
    "#     else 'd' if row['expected_score'] < 19 \n",
    "#     else 'e' \n",
    "# , axis=1)\n",
    "# meaningful_data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"energy_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[0,0],\n",
    ")\n",
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"saturated-fat_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[0,1],\n",
    ")\n",
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"sugars_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[1,0],\n",
    ")\n",
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"salt_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[1,1],\n",
    ")\n",
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"fiber_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[2,0],\n",
    ")\n",
    "\n",
    "sns.jointplot(data=meaningful_data,\n",
    "    x=\"nutrition-score-fr_100g\", \n",
    "    y=\"proteins_100g\", \n",
    "    hue=\"nutrition_grade_fr\",\n",
    "    hue_order=NUTRITION_GRADES,\n",
    "    ax=axes[2,1],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_data = raw_data.drop_duplicates()\n",
    "\n",
    "# Display data types and empty values\n",
    "clean_data.info()\n",
    "\n",
    "clean_data.dropna(\n",
    "        axis='columns',\n",
    "        thresh=.1 * num_rows,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "# Display data types and empty values\n",
    "clean_data.info()\n",
    "\n",
    "num_cols = len(clean_data.columns)\n",
    "clean_data.dropna(\n",
    "        axis='index',\n",
    "        thresh=.1 * num_cols,\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "# Display data types and empty values\n",
    "clean_data.info()\n",
    "\n",
    "clean_data.drop_duplicates(inplace=True,)\n",
    "\n",
    "# Display data types and empty values\n",
    "clean_data.info()\n",
    "\n",
    "# Display statistical summary of each column\n",
    "clean_data.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.imshow(clean_data.isna(),\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meaningful_columns = ['product_name',\n",
    "    'packaging_tags', 'brands_tags', 'manufacturing_places_tags', 'countries_tags',\n",
    "    'main_category', 'categories_tags', \n",
    "    'labels_tags', 'additives_n', 'additives_tags', \n",
    "    'nutrition_grade_fr', 'nutrition-score-fr_100g',\n",
    "    'energy_100g', 'saturated-fat_100g', 'sugars_100g', 'salt_100g', 'sodium_100g',\n",
    "    'fiber_100g', 'proteins_100g',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# display value frequencies per column\n",
    "for col in clean_data.columns:\n",
    "    print(f'\\n \\\n",
    "================================================\\n \\\n",
    ">    { col }\\n \\\n",
    "------------------------------------------------')\n",
    "    display(clean_data[col].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data = pd.read_csv(csv_local_path, \n",
    "    sep='\\t',\n",
    "    usecols=['product_name',\n",
    "        'packaging_tags', 'brands_tags', 'manufacturing_places_tags', 'countries_tags',\n",
    "        'main_category', 'categories_tags', \n",
    "        'labels_tags', 'additives_n', 'additives_tags', \n",
    "        'nutrition_grade_fr', 'nutrition-score-fr_100g',\n",
    "        'energy_100g', 'saturated-fat_100g', 'sugars_100g', 'salt_100g', 'sodium_100g',\n",
    "        'fruits-vegetables-nuts_100g', 'fiber_100g', 'proteins_100g',\n",
    "    ])\n",
    "\n",
    "# display first 5 rows\n",
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effectuer des opérations de nettoyage sur des données structurées\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ les éventuelles valeurs manquantes de chaque colonnes ont été identifiées, quantifiées et traitées\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ les lignes dupliquées ont été identifiées, quantifiées et traitées\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins une fonction a été écrite, testée et utilisée pour nettoyer le jeu de données\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ une méthodologie de traitement des valeurs manquantes pour chaque colonne est justifiée et mise en oeuvre (ex : remplacer les valeurs manquantes d’une colonne par la valeur moyenne de la colonne)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ une méthodologie de traitement des lignes dupliquées est justifiée et mise en oeuvre (ex : les lignes doublons ont été supprimés)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ les fonctionnalités d’édition de cellule Markdown du Jupyter Notebook sont utilisées dans au moins trois cellules pour décrire les choix méthodologiques et rendre lisible le document (titres, mise en forme, alternance de cellule d’exécution de code Python et de cellule de texte explicatif) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ la démarche de nettoyage des données est visible dans la structure du document (découpage du document en partie avec des titres clairs et mis en évidence, des commentaires à l’intérieur des parties pour expliciter la démarche, …)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effectuer une analyse statistique multivariée\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins une méthode d’analyse descriptive est appliquée sur le jeu de données (ex : ACP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins une méthode d’analyse explicative est appliquée sur le jeu de données (ex : ANOVA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins une fonction a été écrite, testée et utilisée pour effectuer une analyse statistique multivariée\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ la méthode d’analyse descriptive appliquée sur le jeu de données est expliquée et justifiée\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ la méthode d’analyse explicative appliquée sur le jeu de données est expliquée et justifiée\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communiquer ses résultats à l’aide de représentations graphiques lisibles et pertinentes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins trois types différents de graphiques ont été utilisés (ex : histogramme, boîte à moustache, nuage de points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ la justification des types de graphiques utilisés est explicitée dans le Jupyter Notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins une fonction a été écrite, testée et utilisée pour effectuer une représentation graphique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ les titres, valeurs des axes des abscisses et des ordonnées et légendes sont explicites\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ au moins un graphique interactif est utilisé pour illustrer une analyse lors de la présentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❒ les titres, valeurs des axes des abscisses et des ordonnées et légendes sont affichés de manière lisible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_[Licence GPL-v3](https://github.com/fleuryc/oc_ingenieur-ia_P2-Participez-a-un-concours-sur-la-Smart-City/blob/main/LICENSE)_\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "main.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a9cd86936e2ed79c88e354605985c1d2e1f30b04e4ab0c2ca683da4978857858"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "c90de28d937fea21fa0e8c0b21949a1a37ba0cff78a53465482821b458660fc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
